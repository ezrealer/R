# 处理大数据集
R将所有的对象存储在虚拟内存中。对于处理大数据集，这将会影响程序的运行速度，带来和内存相关的错误。
具体的内存限制取决于R的版本（32位或64位）和所有的操作系统。出现 `cannot alloctate vector of size` 开头的错误信息通常是因为无法获得连续内存空间，以`cannot allocate vector of length`开头的错误信息则表示超过了内存地址的限制。在处理大型数据集时，应该尽可能地使用64位版，
在处理大数据集时，要考虑三个问题：
a. 高效执行的程序
b. 将数据保存到外部避免内存问题README
c. 用有针对性的统计方法高效地分析海量数据。
#### 1.高效程序设计
下面是在处理大型数据集时有助于提升性能的程序设计建议。
* 尽可能地做向量化计算。用R内建的函数来处理向量、矩阵和列表(例如：`ifelse`、`colMeans`和`rowSums`)，而且要尽量避免使用循环（`for`和`while`）
* 用矩阵，而不是数据框（矩阵更轻量级)。
* 在使用`read.table()`系列函数将外部数据读取到数据框中时，显示地指定`colClasses`和`nrows`,设置`comment.char=""`,并且使用`NULL`标明不需要的列。这可降低内存使用量，显著地提高处理速度。在将外部数据读入矩阵时，可以用`scan()`函数。
* 正确地初始化对象的大小，而不是通过附加值增加较小的对象。
* 并行化处理重复、独立和数值密集的任务。
* 在完整的数据集上运行程序之前，先用数据的子集测试程序，以便优化代码并消除bug。
* 删除临时对象和不在需要的对象。调用`rm(list=ls())`会从内存中删除所有的对象，得到一个干净的环境。要删除特定的对象，可以用`rm(object)`。删除较大对象之后，调用gc()会初始化垃圾回收，保证从内存中清除这些对象。
* `.ls.object()`函数，他可以使工作空间的所有对象按大小(MB)排列。这个函数可以帮你找到内存消耗的大户。
* 测试函数中每个函数消耗的时间。用`Rprof()`和`summaryRprof()`函数就可以完成这个测试。`system.time()`函数也能用得上。`profr`和`profrftools`包提供用于分析测试结果的函数。
* 使用编译的外部例行程序来加速程序运行。`Rcpp`包可以将R对象转换成`C++`函数；如果需要更加优化的子程序，还可以转换回来。

在处理大数据集时,提高代码性能只能走到这一步。在遇到内存限制时,我们还可以将数据保存到外部存储器中,并使用特殊的分析方法。

#### 2.在内存之外的数据
有好几个包可以将数据存储在R的主内存之外。主要的方法是将数据存储在外部数据库中,
或是硬盘上的二进制文件中,然后再按需要访问其中的某个部分。表F-1中列出了一些有用的包。

|包| 描述|
| ------| ------ |
|bigmemory|支持大型矩阵的创建、存储、访问和操作。矩阵可以分配在共享内存和内存映射文件中|
|ff|提供了一种数据结构,可以将数据保存到硬盘上,但用起来却像是在内存中|
|filehash|实现了一个简单的key-value数据库,用字符串的键值关联到硬盘上存储的数据值|
|ncdf 、 ncdf4|提供了Unidate netCDF数据文件的接口|
|RODBC 、 RMySQL 、 ROracle 、 RPostgreSQL 、RSQLite|这些包每一个都可用于访问相应的外部关系型数据库管理系统|

上面介绍的这些包都可用于解决R在保存数据时的内存限制问题。不过,在分析大数据集时,
还需要专门的方法在可接受的时间内完成分析。下面会介绍其中最有用的一些。

#### 3.用于大数据的分析包
R有如下几个用于分析大型数据集的包。
* biglm 和 speedglm 包能以内存高效的方式实现大型数据集的线性模型拟合和广义线性模型拟合。
* 有好几个包是用来分析 `bigmemory` 包生成的大型矩阵的。 `biganalytics`包提供了K均值聚类 、列统计和一个biglm的封装`bigtabulate`包提供 了`table()` 、`split()`和`tapply()`功能;`bigalgebra` 包提供了高级的线性代数函数。
* `biglars` 包跟 `ff`配合使用,为在内存中无法放置的大数据提供了最小角回归(`least-angleregression`)、`lasso`和逐步回归分析。
* `data.table` 包提供了 `data.frame` 的增强版,包括更快的聚集,更快的有序、重叠范围联接,以及更快根据参考组(无副本)进行列相加、修改和删除。我们可以使用带有大型数据集的 `data.table` 结构(例如,内存100GB),它与任意期望得到数据框的R函数都兼容。
这些包能容纳用于特殊目的的大数据集,并且相对容易使用。对于处理TB级分析数据的解决方案,将在下面描述。

#### 4.超大数据集的全面解决方案(TB级)
至少有五个项目旨在方便地使用R来处理TB级数据集,其中有三个是免费开源的(RHIPE、RHadoop 和 pbdr ),另外两是 商业产品(Revolution R Enterprise、RevoScaleR和Oracle R Enterprise)。每个均需要对高性能计算有一定的了解。

RHIPE 包(http://www.datadr.org)提供了将R和Hadoop(一个基于Java的免费软件架构,用于在分布式环境下处理大数据)深度融合的编程环境。该包的作者还开发了其他的软件,提供了对于非常大的数据集进行“分裂与重组”和数据可视化方法。

RHadoop项目提供了R包封装的集合,用于管理和分析Hadoop上的数据。 rmr 包在R内部提供了Hadoop的MapReduce功能, rhdfs 和 rhbase 包支持HDFS文件系统和HBASE数据存储上的访问。维基(https://github.com/RevolutionAnalytics/RHadoop/wiki)上介绍了该项目并提供了相关教程。需要注意的是RHadoop包必须从GitHub上而不是CRAN上安装。

pbdR (programming with big data in R)项目通过一个简单的界面到达可扩展、高性能的库(如MPI、ScaLAPACK和netCDF4),使其能够在R中进行高级别的数据并行运算。pbdR软件在大规模计算集群上还支持单线程多数据(SPMD)模型。可以通过访问http://r-pbd.org/了解详细信息。

Revolution R Enterprise(http://www.revolutionanalytics.com)是R的一个商业版本,包括一个支持可扩展数据分析和高性能计算的包 RevoScaleR 。 RevoScaleR 使用二进制XDF格式的数据文件从磁盘到内存优化流数据,并提供了一系列常见的大数据统计分析算法。你可以执行数据管理任务,并在TB级数据集上获得汇总统计、交叉表格、相关性和协方差、非参数统计、线性和广义线性回归、逐步回归、K-means聚类以及分类和回归树。此外,Revolution R Enterprise可以和Hadoop(通过RHadoop包)及IBM的Netezza(通过IBM PureData分析系统的插件)集成。在写这段文字的时候,学术圈中的学生和教授可以获得免费的软件订阅(不包括IBM组件)。

最后,Oracle R Enterprise(http://www.oracle.com)是一种商业产品,可用于使用R环境操作存储在甲骨文数据库和Hadoop上的大规模数据集。Oracle R Enterprise是甲骨文高级分析的一部分,需要安装在甲骨文的企业版数据库上。几乎R的所有功能,包括数以千计的贡献包,都可以使用Oracle R Enterprise界面应用于TB级的数据问题。这是一个相对昂贵但全面的解决方案,主要吸引财力雄厚的大企业。

不论用哪种语言,处理GB到TB级范围内的数据集都是一种挑战。这些方法都带有一个显著的学习曲线。在四个包中, RevoScaleR 也许是最容易学习和安装的。